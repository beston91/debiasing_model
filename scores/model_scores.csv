Model,toxicity,severe_toxicity,sexually_explicit,threat,profanity,identity_attack,Average
GPT2-medium-BIASED,0.8437639562271907,0.6741595191113424,0.5849290284428683,0.36162402193994997,0.8143004664345302,0.41014477341134237,0.614820294261204
GPT2-medium-DEBIASED,0.8206492902368651,0.6489998196526273,0.5669477254353625,0.34650633893744737,0.7898489146597159,0.396764384733945,0.5949527456093271
